{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from u.data, which contains the full data set. There is a description of the dataset here: http://files.grouplens.org/datasets/movielens/ml-100k-README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep = '\\t', names = header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first couple rows in the dataset. Let's also count the number of unique users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n",
      "Number of users = 943 | Number of movies = 1682\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print('Number of users = ' + str(n_users) + ' | Number of movies = '+ str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into training and testing sets (25 - 75 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  item_id  rating  timestamp\n",
      "85636      749     1013       1  881073081\n",
      "91309      833      517       2  875133633\n",
      "9259       288      887       5  886372155\n",
      "Number of users in the training data: 10000\n",
      "Number of items in the training data: 10000\n",
      "unique users: 1254\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head(3))\n",
    "train_users = train_data.user_id.shape[0]\n",
    "train_items = train_data.item_id.shape[0]\n",
    "print(\"Number of users in the training data: \"+ str(train_data.user_id.shape[0]))\n",
    "print(\"Number of items in the training data: \"+ str(train_data.item_id.shape[0]))\n",
    "print(\"unique users: \"+ str(train_data.item_id.unique().shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is loaded in, lets take a look at a Memory-Based Collaborative Filtering Technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-Based User-Item Collaborative Filtering\n",
    "\n",
    "We will be using an User-Item Collaborative Filtering technique, this is the type used for recommended items where \"Users who are similar to you also liked this\"\n",
    "\n",
    "We will start by making a user-item matrix (user x item). Then we will calculate the similarity of users by counting inversions and create a similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the user-item matrices\n",
    "#create a matrix of zeroes the size of users x items\n",
    "train_matrix = np.zeros((train_users, train_items))\n",
    "for row in train_data.itertuples():\n",
    "    train_matrix[row[1]-1, row[2]-1]=row[3]\n",
    "test_matrix = np.zeros((train_users, train_items))\n",
    "for row in train_data.itertuples():\n",
    "    test_matrix[row[1]-1, row[2]-1]=row[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly take a peek at the sparsity of the matrices. Sparsity in matrices can greatly effect the run-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Sparsity: 0.01%\n",
      "Test_Sparsity: 0.01%\n"
     ]
    }
   ],
   "source": [
    "sparsity = float(len(train_matrix.nonzero()[0]))\n",
    "sparsity /= (train_matrix.shape[0] * train_matrix.shape[1])\n",
    "sparsity *= 100\n",
    "print('Train_Sparsity: {:4.2f}%'.format(sparsity))\n",
    "sparsity = float(len(test_matrix.nonzero()[0]))\n",
    "sparsity /= (test_matrix.shape[0] * test_matrix.shape[1])\n",
    "sparsity *= 100\n",
    "print('Test_Sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the similarity matrices by counting inversions. We are going to user the brute force methods first, and improve as we move along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics.pairwise import pairwise_distances as p\n",
    "#user_sim = p(train_matrix, metric = 'cosine')\n",
    "#user_sim\n",
    "#Cosine calculation of similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareInv(A,B):\n",
    "    numInv = 0\n",
    "    for i in range(0, len(A)-1):\n",
    "        for j in range(i+1, len(A)):\n",
    "            if A[i] > B[j]:\n",
    "                numInv = numInv + 1\n",
    "    return numInv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity train matrix\n",
    "#for each user, we need to calculate the similarity to all other users\n",
    "#so we will take the row, iterate through all other rows\n",
    "#calculate the similarity for every pair of users\n",
    "simArray = pd.DataFrame(columns = [\"Sim\", \"User\"])\n",
    "user = train_matrix[0]\n",
    "sim = 0\n",
    "for column in train_matrix:\n",
    "    for i in range(1, n_users):\n",
    "        sim = compareInv(user, train_matrix[i])\n",
    "        simArray.append({\"Sim\":sim, \"User\":train_matrix[i]}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find items\n",
    "simArray.sort_values(by='Sim', ascending=False)\n",
    "list_items = []\n",
    "for row in simArray:\n",
    "    print(row)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
